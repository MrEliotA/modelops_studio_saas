# KFP v2 IR YAML (YAML-only template)
pipelineInfo:
  name: kserve-deploy-triton
root:
  dag:
    tasks:
      deploy:
        cachingOptions:
          enableCache: false
        componentRef:
          name: comp-deploy-triton
        inputs:
          parameters:
            deployment_base_url:
              componentInputParameter: deployment_base_url
            tenant_id:
              componentInputParameter: tenant_id
            project_id:
              componentInputParameter: project_id
            user_id:
              componentInputParameter: user_id
            deployment_name:
              componentInputParameter: deployment_name
            runtime:
              componentInputParameter: runtime
            model_version_id:
              componentInputParameter: model_version_id
            canary_percent:
              componentInputParameter: canary_percent
            gpu:
              componentInputParameter: gpu
        taskInfo:
          name: deploy
inputDefinitions:
  parameters:
    deployment_base_url:
      parameterType: STRING
    tenant_id:
      parameterType: STRING
    project_id:
      parameterType: STRING
    user_id:
      parameterType: STRING
    deployment_name:
      parameterType: STRING
    runtime:
      parameterType: STRING
    model_version_id:
      parameterType: STRING
    canary_percent:
      parameterType: NUMBER_INTEGER
    gpu:
      parameterType: BOOLEAN
components:
  comp-deploy-triton:
    executorLabel: exec-deploy-triton
    inputDefinitions:
      parameters:
        deployment_base_url:
          parameterType: STRING
        tenant_id:
          parameterType: STRING
        project_id:
          parameterType: STRING
        user_id:
          parameterType: STRING
        deployment_name:
          parameterType: STRING
        runtime:
          parameterType: STRING
        model_version_id:
          parameterType: STRING
        canary_percent:
          parameterType: NUMBER_INTEGER
        gpu:
          parameterType: BOOLEAN
deploymentSpec:
  executors:
    exec-deploy-triton:
      container:
        image: docker.io/library/python:3.11-slim
        command:
          - sh
          - -ec
        args:
          - |
            python - <<'PY'
            import json
            import urllib.request
            import urllib.error

            base = "{{$.inputs.parameters['deployment_base_url']}}".rstrip('/')
            tenant_id = "{{$.inputs.parameters['tenant_id']}}"
            project_id = "{{$.inputs.parameters['project_id']}}"
            user_id = "{{$.inputs.parameters['user_id']}}"
            name = "{{$.inputs.parameters['deployment_name']}}"
            runtime = "{{$.inputs.parameters['runtime']}}"
            model_version_id = "{{$.inputs.parameters['model_version_id']}}".strip()
            canary_percent = int("{{$.inputs.parameters['canary_percent']}}")
            gpu = str("{{$.inputs.parameters['gpu']}}" ).lower() in ('1','true','yes','y')

            if not model_version_id:
              raise SystemExit('model_version_id is required')

            headers = {
              'Content-Type': 'application/json',
              'X-Tenant-Id': tenant_id,
              'X-Project-Id': project_id,
              'X-User-Id': user_id,
            }

            runtime_config = {
              'modelFormat': 'triton',
              'protocolVersion': 'v2',
              'gpu': gpu,
              'resources': {
                'requests': {'cpu': '500m', 'memory': '1Gi'},
                'limits': {'cpu': '2000m', 'memory': '2Gi'}
              }
            }
            if gpu:
              runtime_config['resources']['limits']['nvidia.com/gpu'] = 1
              runtime_config['resources']['requests']['nvidia.com/gpu'] = 1

            traffic = {}
            if canary_percent >= 0:
              traffic = {'canaryTrafficPercent': canary_percent}

            payload = {
              'name': name,
              'runtime': runtime,
              'model_version_id': model_version_id,
              'traffic': traffic,
              'runtime_config': runtime_config,
              'autoscaling': {}
            }

            data = json.dumps(payload).encode('utf-8')
            req = urllib.request.Request(url=f"{base}/api/v1/deployments", data=data, headers=headers, method='POST')
            try:
              with urllib.request.urlopen(req, timeout=20) as resp:
                out = resp.read().decode('utf-8')
                print(out)
            except urllib.error.HTTPError as e:
              out = e.read().decode('utf-8')
              raise SystemExit(f"deploy_failed status={e.code} body={out}")
            PY
schemaVersion: 2.1.0
sdkVersion: kfp-2.15.0
